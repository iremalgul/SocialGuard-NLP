from typing import List, Dict
import pandas as pd
from pathlib import Path
import os
import google.generativeai as genai
import unicodedata
import re
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
from config import DATA_DIR

class FewShotLearningModel:
    """
    Few-Shot Learning model using Gemini API with static training data.
    """
    def __init__(self):
        self.training_data = self._load_training_data()
        self.static_examples = self._select_static_examples()
        
        # TF-IDF vectorizer olu≈ütur
        self._prepare_tfidf_vectorizer()
        
        # Gemini API'yi yapƒ±landƒ±r
        from config import GEMINI_API_KEY
        if GEMINI_API_KEY:
            genai.configure(api_key=GEMINI_API_KEY)
            self.model = genai.GenerativeModel('gemini-2.0-flash-exp')
            print("‚úÖ Gemini 2.0 Flash API configured for few-shot learning")
        else:
            self.model = None
            print("‚ö†Ô∏è GEMINI_API_KEY not found, falling back to majority vote")
    
    def _load_training_data(self) -> List[Dict[str, any]]:
        """Load training data from static CSV file."""
        try:
            dataset_path: Path = DATA_DIR / "dataset.csv"
            df = pd.read_csv(
                dataset_path,
                encoding='utf-8',
                on_bad_lines='skip',  # Skip problematic lines
                engine='python',      # Better error handling
                na_values=['', ' ', 'nan', 'NaN', 'null', 'NULL']
            )
            
            # Convert to list of dictionaries
            training_data = []
            for idx, row in df.iterrows():
                try:
                    # Check if label is not null/empty
                    if pd.isna(row["label"]) or row["label"] == "":
                        continue
                    
                    # Try to convert label to int
                    label_value = row["label"]
                    if isinstance(label_value, str):
                        # Remove any non-numeric characters and try to convert
                        label_clean = ''.join(filter(str.isdigit, str(label_value)))
                        if not label_clean:
                            continue
                        label_int = int(label_clean)
                    else:
                        label_int = int(label_value)
                    
                    # Check if label is in valid range (0-4)
                    if label_int not in range(5):
                        continue
                    
                    training_data.append({
                        "text": str(row["text"]),
                        "label": label_int
                    })
                    
                except (ValueError, KeyError, TypeError) as e:
                    continue
            
            print(f"‚úÖ Loaded {len(training_data)} training examples from {dataset_path}")
            print(f"üìä Dataset shape: {df.shape}")
            print(f"üìä Label distribution:")
            if len(training_data) > 0:
                labels = [ex["label"] for ex in training_data]
                from collections import Counter
                label_counts = Counter(labels)
                for label, count in sorted(label_counts.items()):
                    print(f"   Category {label}: {count} examples")
            return training_data
            
        except Exception as e:
            print(f"‚ùå Error loading training data: {e}")
            return []
    
    def _select_static_examples(self) -> Dict[int, List[Dict[str, any]]]:
        """Her kategoriden 5 manuel se√ßilmi≈ü karakteristik √∂rnek"""
        static_examples = {
            # Kategori 0: Zararsƒ±z/N√∂tr - Olumlu veya n√∂tr yorumlar
            0: [
                {"text": "Bu √ßok g√ºzel bir payla≈üƒ±m olmu≈ü te≈üekk√ºrler", "label": 0},
                {"text": "Harika bir i√ßerik eline saƒülƒ±k", "label": 0},
                {"text": "√áok beƒüendim ba≈üarƒ±lar dilerim", "label": 0},
                {"text": "S√ºper olmu≈ü devamƒ±nƒ± bekliyorum", "label": 0},
                {"text": "ƒ∞yi ak≈üamlar herkese g√ºzel videoymu≈ü", "label": 0}
            ],
            
            # Kategori 1: Doƒürudan Hakaret/K√ºf√ºr - A√ßƒ±k hakaret ve k√ºf√ºr
            1: [
                {"text": "Sen ger√ßekten aptalsƒ±n ya", "label": 1},
                {"text": "Ne kadar salak bir insansƒ±n", "label": 1},
                {"text": "Gerizekalƒ± mƒ±sƒ±n sen", "label": 1},
                {"text": "Mal mƒ±sƒ±n nesin anlamadƒ±m", "label": 1},
                {"text": "Senin gibi dangalaklar y√ºz√ºnden", "label": 1}
            ],
            
            # Kategori 2: Cinsiyet√ßi/Cinsel ƒ∞mada - Cinsiyet ayrƒ±mcƒ±lƒ±ƒüƒ±
            2: [
                {"text": "Kadƒ±nlar hep b√∂yle yapar i≈üte", "label": 2},
                {"text": "Kƒ±zlar anlamaz bunlarƒ± erkek i≈üi", "label": 2},
                {"text": "Sen kadƒ±nsƒ±n ne anlarsƒ±n", "label": 2},
                {"text": "Erkekler b√∂yle ≈üeyleri yapamaz", "label": 2},
                {"text": "Kadƒ±n olduƒüun belli zaten", "label": 2}
            ],
            
            # Kategori 3: Alaycƒ±lƒ±k/Mikroagresyon - ƒ∞ma yoluyla rahatsƒ±z edici
            3: [
                {"text": "Haha ne kadar komiksin (!) ger√ßekten", "label": 3},
                {"text": "Vay be ne kadar zekilsin sen √∂yle", "label": 3},
                {"text": "Aferin sana √ßok ba≈üarƒ±lƒ±sƒ±n (!) devam et", "label": 3},
                {"text": "Hmm anladƒ±k ne kadar √∂zelsin", "label": 3},
                {"text": "Eee tabii sen bilirsin en iyisini", "label": 3}
            ],
            
            # Kategori 4: G√∂r√ºn√ºm Temelli Ele≈ütiri - Fiziksel g√∂r√ºn√ºm
            4: [
                {"text": "√áok √ßirkinsin ya b√∂yle olunmaz", "label": 4},
                {"text": "Ne kadar ≈üi≈ümansƒ±n sen", "label": 4},
                {"text": "√áok zayƒ±fsƒ±n hi√ß g√ºzel deƒüil", "label": 4},
                {"text": "Bu kƒ±yafetle √ßok k√∂t√º g√∂r√ºn√ºyorsun", "label": 4},
                {"text": "Sa√ßlarƒ±n berbat ke≈üke deƒüi≈ütirsen", "label": 4}
            ]
        }
        
        print("üìå Manuel Statik √ñrnekler Y√ºklendi:")
        for cat, examples in static_examples.items():
            category_name = self._get_category_name(cat)
            print(f"   Kategori {cat} ({category_name}): {len(examples)} √∂rnek")
        
        return static_examples
    
    def get_few_shot_examples(self, text: str, limit: int = 3) -> List[Dict[str, any]]:
        """
        Get few-shot examples similar to input text using similarity.
        
        Args:
            text: Input text to find similar examples for
            limit: Number of examples to return
            
        Returns:
            List of examples with text, label, and similarity score
        """
        try:
            if not self.training_data:
                return []
            
            # Calculate similarities
            similarities = []
            for example in self.training_data:
                similarity = self._calculate_similarity(text, example["text"])
                similarities.append({
                    "text": example["text"],
                    "label": example["label"],
                    "similarity": similarity
                })
            
            # Sort by similarity and return top examples
            similarities.sort(key=lambda x: x["similarity"], reverse=True)
            return similarities[:limit]
            
        except Exception as e:
            print(f"Error getting similar examples: {e}")
            return []
    
    def _normalize_text(self, text: str) -> str:
        """Normalize Turkish text for better similarity matching."""
        if not text:
            return ""
        
        # Convert to lowercase
        text = text.lower()
        
        # Remove extra whitespace
        text = re.sub(r'\s+', ' ', text).strip()
        
        # Normalize Turkish characters (optional - can be enabled if needed)
        # text = unicodedata.normalize('NFD', text)
        # text = ''.join(c for c in text if unicodedata.category(c) != 'Mn')
        
        return text
    
    def _prepare_tfidf_vectorizer(self):
        """TF-IDF vectorizer'ƒ± training data ile hazƒ±rla"""
        try:
            if not self.training_data:
                self.vectorizer = None
                self.tfidf_matrix = None
                return
            
            # T√ºm training text'lerini al
            training_texts = [ex['text'] for ex in self.training_data]
            
            # TF-IDF vectorizer olu≈ütur
            self.vectorizer = TfidfVectorizer(
                max_features=1000,
                ngram_range=(1, 2),  # Unigram ve bigram
                lowercase=True,
                analyzer='word',
                token_pattern=r'\b\w+\b'
            )
            
            # Training data'yƒ± vektorize et
            self.tfidf_matrix = self.vectorizer.fit_transform(training_texts)
            
            print("‚úÖ TF-IDF vectorizer hazƒ±rlandƒ±")
            print(f"   - Vocabulary boyutu: {len(self.vectorizer.vocabulary_)}")
            print(f"   - Training data vekt√∂rleri: {self.tfidf_matrix.shape}")
        except Exception as e:
            print(f"‚ö†Ô∏è TF-IDF hazƒ±rlama hatasƒ±: {e}")
            self.vectorizer = None
            self.tfidf_matrix = None
    
    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """
        Calculate text similarity using TF-IDF + Cosine Similarity.
        Fallback: Jaccard similarity if TF-IDF fails.
        """
        try:
            # TF-IDF + Cosine Similarity (Daha geli≈ümi≈ü)
            if self.vectorizer is not None:
                # text1'i vektorize et
                vec1 = self.vectorizer.transform([text1])
                # text2'yi vektorize et
                vec2 = self.vectorizer.transform([text2])
                # Cosine similarity hesapla
                similarity = cosine_similarity(vec1, vec2)[0][0]
                return float(similarity)
        except Exception as e:
            # TF-IDF ba≈üarƒ±sƒ±z olursa Jaccard'a d√º≈ü
            pass
        
        # Fallback: Jaccard Similarity (Basit ama hƒ±zlƒ±)
        norm_text1 = self._normalize_text(text1)
        norm_text2 = self._normalize_text(text2)
        
        words1 = set(norm_text1.split())
        words2 = set(norm_text2.split())
        
        if not words1 or not words2:
            return 0.0
        
        intersection = len(words1.intersection(words2))
        union = len(words1.union(words2))
        
        return intersection / union if union > 0 else 0.0
    
    def create_enhanced_prompt(self, text: str) -> str:
        """
        Create enhanced prompt with static + dynamic few-shot examples.
        
        Args:
            text: Text to analyze
            
        Returns:
            Enhanced prompt string
        """
        print(f"\nüîç Input Text: '{text}'")
        print("="*60)
        
        # 1. Statik √∂rnekler (her kategoriden 5'er)
        static_examples_str = "\nüî∏ SABƒ∞T √ñRNEKLER (Her kategoriden 5'er):\n"
        for category in range(5):
            category_name = self._get_category_name(category)
            static_examples_str += f"\n--- Kategori {category}: {category_name} ---\n"
            
            examples = self.static_examples.get(category, [])[:5]
            for i, ex in enumerate(examples, 1):
                static_examples_str += f'{i}. "{ex["text"]}" -> {category}\n'
        
        print(static_examples_str)
        
        # 2. Dinamik benzer √∂rnekler (en benzer 5)
        similar_examples = self.get_few_shot_examples(text, limit=5)
        
        dynamic_examples_str = "\nüî∏ Dƒ∞NAMƒ∞K BENZER √ñRNEKLER (En benzer 5):\n"
        print("\nüìä En Benzer 5 √ñrnek:")
        print("-" * 60)
        
        for i, ex in enumerate(similar_examples, 1):
            category_name = self._get_category_name(ex["label"])
            similarity = ex.get("similarity", 0)
            dynamic_examples_str += f'{i}. "{ex["text"]}" -> {ex["label"]} ({category_name}) [Benzerlik: {similarity:.2f}]\n'
            
            print(f"{i}. \"{ex['text']}\"")
            print(f"   ‚Üí Category: {ex['label']} ({category_name})")
            print(f"   ‚Üí Similarity: {similarity:.3f}\n")
        
        # Prompt'u olu≈ütur
        examples_for_prompt = "\n\nEƒûƒ∞Tƒ∞M √ñRNEKLERƒ∞:\n"
        
        # Statik √∂rnekleri ekle
        for category in range(5):
            examples = self.static_examples.get(category, [])[:5]
            for ex in examples:
                category_name = self._get_category_name(ex["label"])
                examples_for_prompt += f'"{ex["text"]}" -> {ex["label"]} ({category_name})\n'
        
        # Dinamik benzer √∂rnekleri ekle
        examples_for_prompt += "\nüí° ƒ∞NPUT'A EN BENZER √ñRNEKLER:\n"
        for ex in similar_examples:
            category_name = self._get_category_name(ex["label"])
            similarity = ex.get("similarity", 0)
            examples_for_prompt += f'"{ex["text"]}" -> {ex["label"]} ({category_name}) [Benzerlik: {similarity:.2f}]\n'
        
        # Enhanced prompt
        prompt = f"""
Sen bir yorum sƒ±nƒ±flandƒ±rma uzmanƒ±sƒ±n. A≈üaƒüƒ±daki yorumu analiz et ve kategorilerden birine sƒ±nƒ±flandƒ±r.

KATEGORƒ∞LER:
0: No Harassment / Neutral (Zararsƒ±z/N√∂tr) - Normal, zararsƒ±z yorumlar
1: Direct Insult / Profanity (Doƒürudan Hakaret/K√ºf√ºr) - A√ßƒ±k hakaret ve k√ºf√ºr
2: Sexist / Sexual Implication (Cinsiyet√ßi/Cinsel ƒ∞mada Bulunma) - Cinsiyet√ßi veya cinsel i√ßerik
3: Sarcasm / Microaggression (Alaycƒ±/Mikroagresyon) - Alaycƒ± veya gizli saldƒ±rganlƒ±k
4: Appearance-based Criticism (G√∂r√ºn√ºm Temelli Ele≈ütiri) - Fiziksel g√∂r√ºn√ºm ele≈ütirisi

√ñNEMLƒ∞ KURALLAR:
- "kadƒ±n", "erkek" gibi kelimeler tek ba≈üƒ±na zararlƒ± DEƒûƒ∞LDƒ∞R
- √ñnce eƒüitim √∂rneklerini √∂ƒüren, sonra input'a benzer √∂rneklere odaklan
{examples_for_prompt}

≈ûƒ∞MDƒ∞ ANALƒ∞Z EDƒ∞LECEK YORUM:
"{text}"

Sadece kategori numarasƒ±nƒ± (0-4 arasƒ±) d√∂nd√ºr. A√ßƒ±klama yapma, sadece sayƒ±yƒ± ver.
"""
        print("\n" + "="*60)
        print("‚úÖ Prompt hazƒ±rlandƒ±:")
        print(f"   - Statik √∂rnekler: {sum(len(exs) for exs in self.static_examples.values())} adet")
        print(f"   - Dinamik √∂rnekler: {len(similar_examples)} adet")
        print("="*60 + "\n")
        
        return prompt
    
    def _get_category_name(self, category: int) -> str:
        """Get category name from number."""
        category_names = {
            0: "No Harassment / Neutral",
            1: "Direct Insult / Profanity",
            2: "Sexist / Sexual Implication",
            3: "Sarcasm / Microaggression",
            4: "Appearance-based Criticism"
        }
        return category_names.get(category, "Unknown")
    
    def predict_with_few_shot(self, text: str) -> Dict[str, any]:
        """
        Predict using Gemini with few-shot learning from static training data.
        
        Args:
            text: Text to analyze
            
        Returns:
            Prediction results
        """
        try:
            if self.model:
                try:
                    # Gemini API ile analiz
                    enhanced_prompt = self.create_enhanced_prompt(text)
                    response = self.model.generate_content(enhanced_prompt)
                    prediction_text = response.text.strip()
                    
                    # Sayƒ±yƒ± √ßƒ±kar
                    prediction = int(''.join(filter(str.isdigit, prediction_text[:5])))
                    
                    if prediction in range(5):
                        # Confidence hesaplama - benzer √∂rneklerin ortalamasƒ±na g√∂re
                        similar_examples = self.get_few_shot_examples(text, limit=5)
                        confidence = self._calculate_confidence(text, prediction, similar_examples)
                        
                        return {
                            "category": prediction,
                            "confidence": round(confidence, 3),
                            "message": "Gemini API + Few-shot learning"
                        }
                except Exception as api_error:
                    print(f"Gemini API hatasƒ±: {api_error}")
                    # API hatasƒ± durumunda fallback'e ge√ß
            
            # Fallback: majority vote from similar examples
            examples = self.get_few_shot_examples(text, limit=5)
            if not examples:
                return self._default_response()
            
            from collections import Counter
            labels = [ex["label"] for ex in examples]
            most_common = Counter(labels).most_common(1)[0]
            prediction = most_common[0]
            confidence = most_common[1] / len(labels) * 0.7
            
            return {
                "category": prediction,
                "confidence": round(confidence, 3),
                "message": "Majority vote from similar examples"
            }
                
        except Exception as e:
            print(f"Prediction error: {e}")
            return {
                "category": 0,
                "confidence": 0.5,
                "message": f"Error: {str(e)}"
            }
    
    def _calculate_confidence(self, text: str, predicted_category: int, similar_examples: List[Dict]) -> float:
        """
        Confidence skorunu akƒ±llƒ±ca hesapla.
        
        Fakt√∂rler:
        1. En benzer √∂rneƒüin similarity skoru (aƒüƒ±rlƒ±k: 0.4)
        2. Benzer √∂rneklerdeki kategori tutarlƒ±lƒ±ƒüƒ± (aƒüƒ±rlƒ±k: 0.4)
        3. Base confidence (aƒüƒ±rlƒ±k: 0.2)
        """
        if not similar_examples:
            return 0.50  # D√º≈ü√ºk confidence
        
        # 1. En y√ºksek benzerlik skoru
        max_similarity = similar_examples[0].get('similarity', 0)
        similarity_score = max_similarity  # 0.0 - 1.0
        
        # 2. Kategori tutarlƒ±lƒ±ƒüƒ± (benzer √∂rneklerin ka√ßƒ± aynƒ± kategoriyi g√∂steriyor?)
        same_category_count = sum(1 for ex in similar_examples if ex['label'] == predicted_category)
        consistency_score = same_category_count / len(similar_examples)  # 0.0 - 1.0
        
        # 3. Base confidence
        base_confidence = 0.70
        
        # Aƒüƒ±rlƒ±klƒ± ortalama
        final_confidence = (
            similarity_score * 0.4 +
            consistency_score * 0.4 +
            base_confidence * 0.2
        )
        
        # Minimum ve maksimum sƒ±nƒ±rlarƒ±
        final_confidence = max(0.50, min(0.95, final_confidence))
        
        print(f"üìä Confidence Hesaplama:")
        print(f"   - En y√ºksek benzerlik: {max_similarity:.3f}")
        print(f"   - Tutarlƒ±lƒ±k ({same_category_count}/{len(similar_examples)}): {consistency_score:.3f}")
        print(f"   - Base: {base_confidence:.3f}")
        print(f"   - Final Confidence: {final_confidence:.3f}")
        
        return final_confidence
    
    def _default_response(self) -> Dict[str, any]:
        """Default response when prediction fails."""
        return {
            "category": 0,
            "confidence": 0.5,
            "message": "Varsayƒ±lan kategori"
        }

# Global few-shot learning model instance
few_shot_model = FewShotLearningModel()
