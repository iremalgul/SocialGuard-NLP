{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Türkçe Duygu/Saldırganlık Analizi - Transformer Model Eğitimi\n",
        "## BERTurk ve ElecTRa-TR Modelleri ile Fine-tuning\n",
        "\n",
        "Bu notebook'ta Türkçe siber zorbalık tespiti için iki farklı Transformer modeli eğitilecektir:\n",
        "- **BERTurk**: dbmdz/bert-base-turkish-cased\n",
        "- **ElecTRa-TR**: dbmdz/electra-base-turkish-cased-discriminator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# additional_chat_templates hatasını önle\n",
        "# Slow tokenizer kullanacağız (use_fast=False)\n",
        "print(\"✅ Slow tokenizer kullanılacak (additional_chat_templates problemi yok)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Gerekli Kütüphanelerin Yüklenmesi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Gerekli kütüphaneleri yükle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModelForSequenceClassification,\n",
        "    TrainingArguments, Trainer, EarlyStoppingCallback\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# CUDA kontrolü\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Kullanılan cihaz: {device}\")\n",
        "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'Yok'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Dataset Sınıfı Tanımlama\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TurkishSentimentDataset(Dataset):\n",
        "    \"\"\"Türkçe duygu analizi veri seti\"\"\"\n",
        "    \n",
        "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        label = self.labels[idx]\n",
        "        \n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        \n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "print(\"✅ Dataset sınıfı tanımlandı!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Yardımcı Fonksiyonlar\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_and_preprocess_data(file_path):\n",
        "    \"\"\"Veri setini yükle ve ön işle\"\"\"\n",
        "    print(\"Veri seti yükleniyor...\")\n",
        "    df = pd.read_csv(file_path)\n",
        "    \n",
        "    # Veri temizliği\n",
        "    df = df.dropna()\n",
        "    df['text'] = df['text'].astype(str)\n",
        "    df['label'] = pd.to_numeric(df['label'], errors='coerce')\n",
        "    df = df.dropna()\n",
        "    \n",
        "    # Label'ları temizle (sadece 0-4 arası sayıları kabul et)\n",
        "    df = df[df['label'].isin([0, 1, 2, 3, 4])]\n",
        "    \n",
        "    print(f\"Temizlenmiş veri seti boyutu: {len(df)}\")\n",
        "    print(f\"Label dağılımı:\")\n",
        "    print(df['label'].value_counts().sort_index())\n",
        "    \n",
        "    return df\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Model performans metrikleri\"\"\"\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    \n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted')\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    \n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }\n",
        "\n",
        "def train_model(model_name, train_dataset, val_dataset, num_labels=5, output_dir=None):\n",
        "    \"\"\"Model eğitimi\"\"\"\n",
        "    print(f\"\\n{model_name} modeli eğitiliyor...\")\n",
        "    \n",
        "    # Tokenizer ve model yükle (use_fast=False ile additional_chat_templates hatası önlenir)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        model_name,\n",
        "        num_labels=num_labels,\n",
        "        problem_type=\"single_label_classification\"\n",
        "    )\n",
        "    \n",
        "    # Model'i GPU'ya taşı\n",
        "    model.to(device)\n",
        "    \n",
        "    # Eğitim parametreleri\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=output_dir or f'./results_{model_name.replace(\"/\", \"_\")}',\n",
        "        num_train_epochs=3,\n",
        "        per_device_train_batch_size=8,\n",
        "        per_device_eval_batch_size=16,\n",
        "        warmup_steps=500,\n",
        "        weight_decay=0.01,\n",
        "        logging_dir=f'./logs_{model_name.replace(\"/\", \"_\")}',\n",
        "        logging_steps=100,\n",
        "        evaluation_strategy=\"steps\",\n",
        "        eval_steps=500,\n",
        "        save_strategy=\"steps\",\n",
        "        save_steps=500,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"f1\",\n",
        "        greater_is_better=True,\n",
        "        report_to=None,  # TensorBoard'u kapat\n",
        "        save_total_limit=2,\n",
        "        learning_rate=2e-5,\n",
        "        fp16=torch.cuda.is_available(),  # GPU varsa mixed precision kullan\n",
        "    )\n",
        "    \n",
        "    # Trainer oluştur\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        compute_metrics=compute_metrics,\n",
        "        callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
        "    )\n",
        "    \n",
        "    # Eğitimi başlat\n",
        "    print(\"Eğitim başlıyor...\")\n",
        "    trainer.train()\n",
        "    \n",
        "    # En iyi modeli kaydet\n",
        "    trainer.save_model()\n",
        "    tokenizer.save_pretrained(output_dir or f'./results_{model_name.replace(\"/\", \"_\")}')\n",
        "    \n",
        "    # Test seti üzerinde değerlendirme\n",
        "    print(\"\\nModel değerlendiriliyor...\")\n",
        "    eval_results = trainer.evaluate()\n",
        "    print(f\"Değerlendirme sonuçları: {eval_results}\")\n",
        "    \n",
        "    return trainer, tokenizer, model\n",
        "\n",
        "print(\"✅ Fonksiyonlar tanımlandı!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Eğitim Veri Setini Yükleme\n",
        "\n",
        "**Kaggle'da veri setini yüklemek için:**\n",
        "1. Data -> Add Data -> Upload Data ile CSV dosyasını yükleyin\n",
        "2. Veya Dataset olarak Kaggle'da yayınlayıp buradan import edin\n",
        "3. Dosya yolunu aşağıdaki gibi güncelleyin: `/kaggle/input/your-dataset-name/nlpaug_turkish_augmented.csv`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Kaggle'da dosya yolu - kendi dataset adınıza göre güncelleyin\n",
        "# Örnek: file_path = '/kaggle/input/turkish-cyberbullying/nlpaug_turkish_augmented.csv'\n",
        "file_path = '/kaggle/input/turkish-cyberbullying-dataset/nlpaug_turkish_augmented.csv'\n",
        "\n",
        "# Veri setini yükle\n",
        "df = load_and_preprocess_data(file_path)\n",
        "\n",
        "# Train/validation split\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    df['text'].values, df['label'].values, \n",
        "    test_size=0.2, random_state=42, stratify=df['label']\n",
        ")\n",
        "\n",
        "print(f\"\\nEğitim seti: {len(train_texts)} örnek\")\n",
        "print(f\"Validation seti: {len(val_texts)} örnek\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Model Eğitimi\n",
        "\n",
        "### 5.1 BERTurk Modeli\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*60)\n",
        "print(\"MODEL 1: BERTurk\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "model_name_berturk = \"dbmdz/bert-base-turkish-cased\"\n",
        "\n",
        "try:\n",
        "    # Tokenizer yükle (use_fast=False ile additional_chat_templates hatası önlenir)\n",
        "    tokenizer_berturk = AutoTokenizer.from_pretrained(model_name_berturk, use_fast=False)\n",
        "    \n",
        "    # Dataset'leri oluştur\n",
        "    train_dataset_berturk = TurkishSentimentDataset(train_texts, train_labels, tokenizer_berturk)\n",
        "    val_dataset_berturk = TurkishSentimentDataset(val_texts, val_labels, tokenizer_berturk)\n",
        "    \n",
        "    # Model eğit\n",
        "    trainer_berturk, tokenizer_berturk, model_berturk = train_model(\n",
        "        model_name_berturk, train_dataset_berturk, val_dataset_berturk,\n",
        "        num_labels=5,\n",
        "        output_dir='./turkish_sentiment_bert-base-turkish-cased'\n",
        "    )\n",
        "    \n",
        "    # Sonuçları kaydet\n",
        "    results_berturk = trainer_berturk.evaluate()\n",
        "    \n",
        "    print(\"\\n✅ BERTurk modeli başarıyla eğitildi!\")\n",
        "    print(f\"📊 Sonuçlar: {results_berturk}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"❌ Hata: BERTurk eğitilirken hata oluştu: {str(e)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.2 ElecTRa-TR Modeli\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GPU belleğini temizle\n",
        "if 'model_berturk' in locals():\n",
        "    del model_berturk, trainer_berturk\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"MODEL 2: ElecTRa-TR\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "model_name_electra = \"dbmdz/electra-base-turkish-cased-discriminator\"\n",
        "\n",
        "try:\n",
        "    # Tokenizer yükle (use_fast=False ile additional_chat_templates hatası önlenir)\n",
        "    tokenizer_electra = AutoTokenizer.from_pretrained(model_name_electra, use_fast=False)\n",
        "    \n",
        "    # Dataset'leri oluştur\n",
        "    train_dataset_electra = TurkishSentimentDataset(train_texts, train_labels, tokenizer_electra)\n",
        "    val_dataset_electra = TurkishSentimentDataset(val_texts, val_labels, tokenizer_electra)\n",
        "    \n",
        "    # Model eğit\n",
        "    trainer_electra, tokenizer_electra, model_electra = train_model(\n",
        "        model_name_electra, train_dataset_electra, val_dataset_electra,\n",
        "        num_labels=5,\n",
        "        output_dir='./turkish_sentiment_electra-base-turkish-cased-discriminator'\n",
        "    )\n",
        "    \n",
        "    # Sonuçları kaydet\n",
        "    results_electra = trainer_electra.evaluate()\n",
        "    \n",
        "    print(\"\\n✅ ElecTRa-TR modeli başarıyla eğitildi!\")\n",
        "    print(f\"📊 Sonuçlar: {results_electra}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"❌ Hata: ElecTRa-TR eğitilirken hata oluştu: {str(e)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Model Karşılaştırması\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sonuçları karşılaştır\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MODEL KARŞILAŞTIRMASI (Validation Set)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Model': ['BERTurk', 'ElecTRa-TR'],\n",
        "    'Accuracy': [results_berturk.get('eval_accuracy', 0), results_electra.get('eval_accuracy', 0)],\n",
        "    'F1': [results_berturk.get('eval_f1', 0), results_electra.get('eval_f1', 0)],\n",
        "    'Precision': [results_berturk.get('eval_precision', 0), results_electra.get('eval_precision', 0)],\n",
        "    'Recall': [results_berturk.get('eval_recall', 0), results_electra.get('eval_recall', 0)]\n",
        "})\n",
        "\n",
        "print(comparison_df.to_string(index=False))\n",
        "\n",
        "# En iyi modeli belirle\n",
        "best_model_idx = comparison_df['F1'].idxmax()\n",
        "print(f\"\\n🏆 En iyi model: {comparison_df.iloc[best_model_idx]['Model']} (F1: {comparison_df.iloc[best_model_idx]['F1']:.4f})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Test Seti Yükleme ve Hazırlık\n",
        "\n",
        "**Not:** Test setinizi (`test_set_siber_zorbalik_v2.csv`) Kaggle'a yükleyin ve yolu güncelleyin.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test veri setini yükle\n",
        "# Kaggle'da dosya yolu - kendi dataset adınıza göre güncelleyin\n",
        "test_file_path = '/kaggle/input/turkish-cyberbullying-dataset/test_set_siber_zorbalik_v2.csv'\n",
        "\n",
        "print(\"📂 Test veri seti yükleniyor...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# CSV'yi oku\n",
        "df_test = pd.read_csv(test_file_path)\n",
        "\n",
        "print(f\"📊 Orijinal test seti boyutu: {df_test.shape}\")\n",
        "\n",
        "# Veri temizliği\n",
        "df_test['label'] = pd.to_numeric(df_test['label'], errors='coerce')\n",
        "df_test = df_test[df_test['label'].isin([0, 1, 2, 3, 4])]\n",
        "df_test = df_test.dropna(subset=['comment', 'label'])\n",
        "df_test['label'] = df_test['label'].astype(int)\n",
        "df_test = df_test[df_test['comment'].str.strip() != '']\n",
        "df_test = df_test.reset_index(drop=True)\n",
        "\n",
        "print(f\"✅ Temizlenmiş test seti boyutu: {df_test.shape}\")\n",
        "print(f\"\\n📈 Test seti sınıf dağılımı:\")\n",
        "print(df_test['label'].value_counts().sort_index())\n",
        "\n",
        "# Test verilerini hazırla\n",
        "test_texts = df_test['comment'].values\n",
        "test_labels = df_test['label'].values\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Test Seti Tahminleri\n",
        "\n",
        "### 8.1 BERTurk ile Test Seti Tahmini\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.2 ElecTRa-TR ile Test Seti Tahmini\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"BERTURK - TEST SETİ TAHMİNLERİ\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Sınıf isimleri\n",
        "class_names = [\n",
        "    'No Harassment / Neutral',\n",
        "    'Direct Insult / Profanity',\n",
        "    'Sexist / Sexual Implication',\n",
        "    'Sarcasm / Microaggression',\n",
        "    'Appearance-based Criticism'\n",
        "]\n",
        "\n",
        "# Model'i eval moduna al\n",
        "model_berturk.eval()\n",
        "model_berturk.to(device)\n",
        "\n",
        "# Test dataset oluştur\n",
        "test_dataset_berturk = TurkishSentimentDataset(test_texts, test_labels, tokenizer_berturk)\n",
        "\n",
        "# Tahminleri al\n",
        "predictions_berturk = trainer_berturk.predict(test_dataset_berturk)\n",
        "y_pred_berturk = np.argmax(predictions_berturk.predictions, axis=1)\n",
        "\n",
        "# Accuracy hesapla\n",
        "accuracy_berturk = accuracy_score(test_labels, y_pred_berturk)\n",
        "\n",
        "print(f\"\\n📊 Test Accuracy: {accuracy_berturk:.4f}\")\n",
        "print(f\"\\n📋 Classification Report:\\n\")\n",
        "print(classification_report(test_labels, y_pred_berturk, target_names=class_names))\n",
        "\n",
        "# Her örnek için detaylı sonuç\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"DETAYLI TAHMİN SONUÇLARI\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "results_list_berturk = []\n",
        "for i in range(len(test_texts)):\n",
        "    result = {\n",
        "        'Metin': test_texts[i],\n",
        "        'Gerçek': class_names[test_labels[i]],\n",
        "        'Tahmin': class_names[y_pred_berturk[i]],\n",
        "        'Doğru': '✓' if test_labels[i] == y_pred_berturk[i] else '✗'\n",
        "    }\n",
        "    results_list_berturk.append(result)\n",
        "    print(f\"\\n{i+1}. {result['Metin'][:50]}...\")\n",
        "    print(f\"   Gerçek: {result['Gerçek']}\")\n",
        "    print(f\"   Tahmin: {result['Tahmin']} {result['Doğru']}\")\n",
        "\n",
        "# DataFrame olarak kaydet\n",
        "df_results_berturk = pd.DataFrame(results_list_berturk)\n",
        "df_results_berturk.to_csv('berturk_test_predictions.csv', index=False, encoding='utf-8-sig')\n",
        "print(\"\\n💾 BERTurk tahminleri 'berturk_test_predictions.csv' dosyasına kaydedildi!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ELECTRA-TR - TEST SETİ TAHMİNLERİ\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Model'i eval moduna al\n",
        "model_electra.eval()\n",
        "model_electra.to(device)\n",
        "\n",
        "# Test dataset oluştur\n",
        "test_dataset_electra = TurkishSentimentDataset(test_texts, test_labels, tokenizer_electra)\n",
        "\n",
        "# Tahminleri al\n",
        "predictions_electra = trainer_electra.predict(test_dataset_electra)\n",
        "y_pred_electra = np.argmax(predictions_electra.predictions, axis=1)\n",
        "\n",
        "# Accuracy hesapla\n",
        "accuracy_electra = accuracy_score(test_labels, y_pred_electra)\n",
        "\n",
        "print(f\"\\n📊 Test Accuracy: {accuracy_electra:.4f}\")\n",
        "print(f\"\\n📋 Classification Report:\\n\")\n",
        "print(classification_report(test_labels, y_pred_electra, target_names=class_names))\n",
        "\n",
        "# Her örnek için detaylı sonuç\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"DETAYLI TAHMİN SONUÇLARI\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "results_list_electra = []\n",
        "for i in range(len(test_texts)):\n",
        "    result = {\n",
        "        'Metin': test_texts[i],\n",
        "        'Gerçek': class_names[test_labels[i]],\n",
        "        'Tahmin': class_names[y_pred_electra[i]],\n",
        "        'Doğru': '✓' if test_labels[i] == y_pred_electra[i] else '✗'\n",
        "    }\n",
        "    results_list_electra.append(result)\n",
        "    print(f\"\\n{i+1}. {result['Metin'][:50]}...\")\n",
        "    print(f\"   Gerçek: {result['Gerçek']}\")\n",
        "    print(f\"   Tahmin: {result['Tahmin']} {result['Doğru']}\")\n",
        "\n",
        "# DataFrame olarak kaydet\n",
        "df_results_electra = pd.DataFrame(results_list_electra)\n",
        "df_results_electra.to_csv('electra_test_predictions.csv', index=False, encoding='utf-8-sig')\n",
        "print(\"\\n💾 ElecTRa-TR tahminleri 'electra_test_predictions.csv' dosyasına kaydedildi!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Test Seti Sonuçlarının Karşılaştırılması\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TEST SETİ - MODEL KARŞILAŞTIRMASI\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "test_comparison_df = pd.DataFrame({\n",
        "    'Model': ['BERTurk', 'ElecTRa-TR'],\n",
        "    'Test Accuracy': [accuracy_berturk, accuracy_electra],\n",
        "    'Doğru Tahmin': [\n",
        "        (y_pred_berturk == test_labels).sum(),\n",
        "        (y_pred_electra == test_labels).sum()\n",
        "    ],\n",
        "    'Yanlış Tahmin': [\n",
        "        (y_pred_berturk != test_labels).sum(),\n",
        "        (y_pred_electra != test_labels).sum()\n",
        "    ],\n",
        "    'Toplam': [len(test_labels), len(test_labels)]\n",
        "})\n",
        "\n",
        "print(\"\\n\" + test_comparison_df.to_string(index=False))\n",
        "\n",
        "# En iyi test performansı\n",
        "best_test_idx = test_comparison_df['Test Accuracy'].idxmax()\n",
        "print(f\"\\n🏆 Test setinde en iyi model: {test_comparison_df.iloc[best_test_idx]['Model']}\")\n",
        "print(f\"   Accuracy: {test_comparison_df.iloc[best_test_idx]['Test Accuracy']:.4f}\")\n",
        "\n",
        "# Karşılaştırmalı sonuçları kaydet\n",
        "test_comparison_df.to_csv('test_set_comparison.csv', index=False)\n",
        "print(\"\\n💾 Karşılaştırma sonuçları 'test_set_comparison.csv' dosyasına kaydedildi!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Özet ve Kaydedilen Dosyalar\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"📊 PROJE ÖZETİ\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\n✅ Toplam eğitim verisi: {len(df)}\")\n",
        "print(f\"✅ Training set: {len(train_texts)} örnek\")\n",
        "print(f\"✅ Validation set: {len(val_texts)} örnek\")\n",
        "print(f\"✅ Test set: {len(test_texts)} örnek\")\n",
        "\n",
        "print(f\"\\n✅ Eğitilen modeller:\")\n",
        "print(f\"   1. BERTurk (dbmdz/bert-base-turkish-cased)\")\n",
        "print(f\"      - Validation F1: {results_berturk.get('eval_f1', 0):.4f}\")\n",
        "print(f\"      - Test Accuracy: {accuracy_berturk:.4f}\")\n",
        "print(f\"   2. ElecTRa-TR (dbmdz/electra-base-turkish-cased-discriminator)\")\n",
        "print(f\"      - Validation F1: {results_electra.get('eval_f1', 0):.4f}\")\n",
        "print(f\"      - Test Accuracy: {accuracy_electra:.4f}\")\n",
        "\n",
        "print(f\"\\n✅ Kaydedilen model dizinleri:\")\n",
        "print(\"   - ./turkish_sentiment_bert-base-turkish-cased/\")\n",
        "print(\"   - ./turkish_sentiment_electra-base-turkish-cased-discriminator/\")\n",
        "\n",
        "print(f\"\\n✅ Kaydedilen tahmin dosyaları:\")\n",
        "print(\"   - berturk_test_predictions.csv\")\n",
        "print(\"   - electra_test_predictions.csv\")\n",
        "print(\"   - test_set_comparison.csv\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"🎉 TÜM İŞLEMLER BAŞARIYLA TAMAMLANDI!\")\n",
        "print(\"=\"*60)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
