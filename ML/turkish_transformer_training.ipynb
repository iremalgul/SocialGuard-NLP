{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TÃ¼rkÃ§e Duygu/SaldÄ±rganlÄ±k Analizi - Transformer Model EÄŸitimi\n",
        "## BERTurk ve ElecTRa-TR Modelleri ile Fine-tuning\n",
        "\n",
        "Bu notebook'ta TÃ¼rkÃ§e siber zorbalÄ±k tespiti iÃ§in iki farklÄ± Transformer modeli eÄŸitilecektir:\n",
        "- **BERTurk**: dbmdz/bert-base-turkish-cased\n",
        "- **ElecTRa-TR**: dbmdz/electra-base-turkish-cased-discriminator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# additional_chat_templates hatasÄ±nÄ± Ã¶nle\n",
        "# Slow tokenizer kullanacaÄŸÄ±z (use_fast=False)\n",
        "print(\"âœ… Slow tokenizer kullanÄ±lacak (additional_chat_templates problemi yok)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Gerekli KÃ¼tÃ¼phanelerin YÃ¼klenmesi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Gerekli kÃ¼tÃ¼phaneleri yÃ¼kle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModelForSequenceClassification,\n",
        "    TrainingArguments, Trainer, EarlyStoppingCallback\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# CUDA kontrolÃ¼\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"KullanÄ±lan cihaz: {device}\")\n",
        "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'Yok'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Dataset SÄ±nÄ±fÄ± TanÄ±mlama\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TurkishSentimentDataset(Dataset):\n",
        "    \"\"\"TÃ¼rkÃ§e duygu analizi veri seti\"\"\"\n",
        "    \n",
        "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        label = self.labels[idx]\n",
        "        \n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        \n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "print(\"âœ… Dataset sÄ±nÄ±fÄ± tanÄ±mlandÄ±!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. YardÄ±mcÄ± Fonksiyonlar\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_and_preprocess_data(file_path):\n",
        "    \"\"\"Veri setini yÃ¼kle ve Ã¶n iÅŸle\"\"\"\n",
        "    print(\"Veri seti yÃ¼kleniyor...\")\n",
        "    df = pd.read_csv(file_path)\n",
        "    \n",
        "    # Veri temizliÄŸi\n",
        "    df = df.dropna()\n",
        "    df['text'] = df['text'].astype(str)\n",
        "    df['label'] = pd.to_numeric(df['label'], errors='coerce')\n",
        "    df = df.dropna()\n",
        "    \n",
        "    # Label'larÄ± temizle (sadece 0-4 arasÄ± sayÄ±larÄ± kabul et)\n",
        "    df = df[df['label'].isin([0, 1, 2, 3, 4])]\n",
        "    \n",
        "    print(f\"TemizlenmiÅŸ veri seti boyutu: {len(df)}\")\n",
        "    print(f\"Label daÄŸÄ±lÄ±mÄ±:\")\n",
        "    print(df['label'].value_counts().sort_index())\n",
        "    \n",
        "    return df\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Model performans metrikleri\"\"\"\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    \n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted')\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    \n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }\n",
        "\n",
        "def train_model(model_name, train_dataset, val_dataset, num_labels=5, output_dir=None):\n",
        "    \"\"\"Model eÄŸitimi\"\"\"\n",
        "    print(f\"\\n{model_name} modeli eÄŸitiliyor...\")\n",
        "    \n",
        "    # Tokenizer ve model yÃ¼kle (use_fast=False ile additional_chat_templates hatasÄ± Ã¶nlenir)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        model_name,\n",
        "        num_labels=num_labels,\n",
        "        problem_type=\"single_label_classification\"\n",
        "    )\n",
        "    \n",
        "    # Model'i GPU'ya taÅŸÄ±\n",
        "    model.to(device)\n",
        "    \n",
        "    # EÄŸitim parametreleri\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=output_dir or f'./results_{model_name.replace(\"/\", \"_\")}',\n",
        "        num_train_epochs=3,\n",
        "        per_device_train_batch_size=8,\n",
        "        per_device_eval_batch_size=16,\n",
        "        warmup_steps=500,\n",
        "        weight_decay=0.01,\n",
        "        logging_dir=f'./logs_{model_name.replace(\"/\", \"_\")}',\n",
        "        logging_steps=100,\n",
        "        evaluation_strategy=\"steps\",\n",
        "        eval_steps=500,\n",
        "        save_strategy=\"steps\",\n",
        "        save_steps=500,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"f1\",\n",
        "        greater_is_better=True,\n",
        "        report_to=None,  # TensorBoard'u kapat\n",
        "        save_total_limit=2,\n",
        "        learning_rate=2e-5,\n",
        "        fp16=torch.cuda.is_available(),  # GPU varsa mixed precision kullan\n",
        "    )\n",
        "    \n",
        "    # Trainer oluÅŸtur\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        compute_metrics=compute_metrics,\n",
        "        callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
        "    )\n",
        "    \n",
        "    # EÄŸitimi baÅŸlat\n",
        "    print(\"EÄŸitim baÅŸlÄ±yor...\")\n",
        "    trainer.train()\n",
        "    \n",
        "    # En iyi modeli kaydet\n",
        "    trainer.save_model()\n",
        "    tokenizer.save_pretrained(output_dir or f'./results_{model_name.replace(\"/\", \"_\")}')\n",
        "    \n",
        "    # Test seti Ã¼zerinde deÄŸerlendirme\n",
        "    print(\"\\nModel deÄŸerlendiriliyor...\")\n",
        "    eval_results = trainer.evaluate()\n",
        "    print(f\"DeÄŸerlendirme sonuÃ§larÄ±: {eval_results}\")\n",
        "    \n",
        "    return trainer, tokenizer, model\n",
        "\n",
        "print(\"âœ… Fonksiyonlar tanÄ±mlandÄ±!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. EÄŸitim Veri Setini YÃ¼kleme\n",
        "\n",
        "**Kaggle'da veri setini yÃ¼klemek iÃ§in:**\n",
        "1. Data -> Add Data -> Upload Data ile CSV dosyasÄ±nÄ± yÃ¼kleyin\n",
        "2. Veya Dataset olarak Kaggle'da yayÄ±nlayÄ±p buradan import edin\n",
        "3. Dosya yolunu aÅŸaÄŸÄ±daki gibi gÃ¼ncelleyin: `/kaggle/input/your-dataset-name/nlpaug_turkish_augmented.csv`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Kaggle'da dosya yolu - kendi dataset adÄ±nÄ±za gÃ¶re gÃ¼ncelleyin\n",
        "# Ã–rnek: file_path = '/kaggle/input/turkish-cyberbullying/nlpaug_turkish_augmented.csv'\n",
        "file_path = '/kaggle/input/turkish-cyberbullying-dataset/nlpaug_turkish_augmented.csv'\n",
        "\n",
        "# Veri setini yÃ¼kle\n",
        "df = load_and_preprocess_data(file_path)\n",
        "\n",
        "# Train/validation split\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    df['text'].values, df['label'].values, \n",
        "    test_size=0.2, random_state=42, stratify=df['label']\n",
        ")\n",
        "\n",
        "print(f\"\\nEÄŸitim seti: {len(train_texts)} Ã¶rnek\")\n",
        "print(f\"Validation seti: {len(val_texts)} Ã¶rnek\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Model EÄŸitimi\n",
        "\n",
        "### 5.1 BERTurk Modeli\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*60)\n",
        "print(\"MODEL 1: BERTurk\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "model_name_berturk = \"dbmdz/bert-base-turkish-cased\"\n",
        "\n",
        "try:\n",
        "    # Tokenizer yÃ¼kle (use_fast=False ile additional_chat_templates hatasÄ± Ã¶nlenir)\n",
        "    tokenizer_berturk = AutoTokenizer.from_pretrained(model_name_berturk, use_fast=False)\n",
        "    \n",
        "    # Dataset'leri oluÅŸtur\n",
        "    train_dataset_berturk = TurkishSentimentDataset(train_texts, train_labels, tokenizer_berturk)\n",
        "    val_dataset_berturk = TurkishSentimentDataset(val_texts, val_labels, tokenizer_berturk)\n",
        "    \n",
        "    # Model eÄŸit\n",
        "    trainer_berturk, tokenizer_berturk, model_berturk = train_model(\n",
        "        model_name_berturk, train_dataset_berturk, val_dataset_berturk,\n",
        "        num_labels=5,\n",
        "        output_dir='./turkish_sentiment_bert-base-turkish-cased'\n",
        "    )\n",
        "    \n",
        "    # SonuÃ§larÄ± kaydet\n",
        "    results_berturk = trainer_berturk.evaluate()\n",
        "    \n",
        "    print(\"\\nâœ… BERTurk modeli baÅŸarÄ±yla eÄŸitildi!\")\n",
        "    print(f\"ğŸ“Š SonuÃ§lar: {results_berturk}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"âŒ Hata: BERTurk eÄŸitilirken hata oluÅŸtu: {str(e)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.2 ElecTRa-TR Modeli\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GPU belleÄŸini temizle\n",
        "if 'model_berturk' in locals():\n",
        "    del model_berturk, trainer_berturk\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"MODEL 2: ElecTRa-TR\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "model_name_electra = \"dbmdz/electra-base-turkish-cased-discriminator\"\n",
        "\n",
        "try:\n",
        "    # Tokenizer yÃ¼kle (use_fast=False ile additional_chat_templates hatasÄ± Ã¶nlenir)\n",
        "    tokenizer_electra = AutoTokenizer.from_pretrained(model_name_electra, use_fast=False)\n",
        "    \n",
        "    # Dataset'leri oluÅŸtur\n",
        "    train_dataset_electra = TurkishSentimentDataset(train_texts, train_labels, tokenizer_electra)\n",
        "    val_dataset_electra = TurkishSentimentDataset(val_texts, val_labels, tokenizer_electra)\n",
        "    \n",
        "    # Model eÄŸit\n",
        "    trainer_electra, tokenizer_electra, model_electra = train_model(\n",
        "        model_name_electra, train_dataset_electra, val_dataset_electra,\n",
        "        num_labels=5,\n",
        "        output_dir='./turkish_sentiment_electra-base-turkish-cased-discriminator'\n",
        "    )\n",
        "    \n",
        "    # SonuÃ§larÄ± kaydet\n",
        "    results_electra = trainer_electra.evaluate()\n",
        "    \n",
        "    print(\"\\nâœ… ElecTRa-TR modeli baÅŸarÄ±yla eÄŸitildi!\")\n",
        "    print(f\"ğŸ“Š SonuÃ§lar: {results_electra}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"âŒ Hata: ElecTRa-TR eÄŸitilirken hata oluÅŸtu: {str(e)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Model KarÅŸÄ±laÅŸtÄ±rmasÄ±\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SonuÃ§larÄ± karÅŸÄ±laÅŸtÄ±r\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MODEL KARÅILAÅTIRMASI (Validation Set)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Model': ['BERTurk', 'ElecTRa-TR'],\n",
        "    'Accuracy': [results_berturk.get('eval_accuracy', 0), results_electra.get('eval_accuracy', 0)],\n",
        "    'F1': [results_berturk.get('eval_f1', 0), results_electra.get('eval_f1', 0)],\n",
        "    'Precision': [results_berturk.get('eval_precision', 0), results_electra.get('eval_precision', 0)],\n",
        "    'Recall': [results_berturk.get('eval_recall', 0), results_electra.get('eval_recall', 0)]\n",
        "})\n",
        "\n",
        "print(comparison_df.to_string(index=False))\n",
        "\n",
        "# En iyi modeli belirle\n",
        "best_model_idx = comparison_df['F1'].idxmax()\n",
        "print(f\"\\nğŸ† En iyi model: {comparison_df.iloc[best_model_idx]['Model']} (F1: {comparison_df.iloc[best_model_idx]['F1']:.4f})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Test Seti YÃ¼kleme ve HazÄ±rlÄ±k\n",
        "\n",
        "**Not:** Test setinizi (`test_set_siber_zorbalik_v2.csv`) Kaggle'a yÃ¼kleyin ve yolu gÃ¼ncelleyin.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test veri setini yÃ¼kle\n",
        "# Kaggle'da dosya yolu - kendi dataset adÄ±nÄ±za gÃ¶re gÃ¼ncelleyin\n",
        "test_file_path = '/kaggle/input/turkish-cyberbullying-dataset/test_set_siber_zorbalik_v2.csv'\n",
        "\n",
        "print(\"ğŸ“‚ Test veri seti yÃ¼kleniyor...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# CSV'yi oku\n",
        "df_test = pd.read_csv(test_file_path)\n",
        "\n",
        "print(f\"ğŸ“Š Orijinal test seti boyutu: {df_test.shape}\")\n",
        "\n",
        "# Veri temizliÄŸi\n",
        "df_test['label'] = pd.to_numeric(df_test['label'], errors='coerce')\n",
        "df_test = df_test[df_test['label'].isin([0, 1, 2, 3, 4])]\n",
        "df_test = df_test.dropna(subset=['comment', 'label'])\n",
        "df_test['label'] = df_test['label'].astype(int)\n",
        "df_test = df_test[df_test['comment'].str.strip() != '']\n",
        "df_test = df_test.reset_index(drop=True)\n",
        "\n",
        "print(f\"âœ… TemizlenmiÅŸ test seti boyutu: {df_test.shape}\")\n",
        "print(f\"\\nğŸ“ˆ Test seti sÄ±nÄ±f daÄŸÄ±lÄ±mÄ±:\")\n",
        "print(df_test['label'].value_counts().sort_index())\n",
        "\n",
        "# Test verilerini hazÄ±rla\n",
        "test_texts = df_test['comment'].values\n",
        "test_labels = df_test['label'].values\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Test Seti Tahminleri\n",
        "\n",
        "### 8.1 BERTurk ile Test Seti Tahmini\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.2 ElecTRa-TR ile Test Seti Tahmini\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"BERTURK - TEST SETÄ° TAHMÄ°NLERÄ°\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# SÄ±nÄ±f isimleri\n",
        "class_names = [\n",
        "    'No Harassment / Neutral',\n",
        "    'Direct Insult / Profanity',\n",
        "    'Sexist / Sexual Implication',\n",
        "    'Sarcasm / Microaggression',\n",
        "    'Appearance-based Criticism'\n",
        "]\n",
        "\n",
        "# Model'i eval moduna al\n",
        "model_berturk.eval()\n",
        "model_berturk.to(device)\n",
        "\n",
        "# Test dataset oluÅŸtur\n",
        "test_dataset_berturk = TurkishSentimentDataset(test_texts, test_labels, tokenizer_berturk)\n",
        "\n",
        "# Tahminleri al\n",
        "predictions_berturk = trainer_berturk.predict(test_dataset_berturk)\n",
        "y_pred_berturk = np.argmax(predictions_berturk.predictions, axis=1)\n",
        "\n",
        "# Accuracy hesapla\n",
        "accuracy_berturk = accuracy_score(test_labels, y_pred_berturk)\n",
        "\n",
        "print(f\"\\nğŸ“Š Test Accuracy: {accuracy_berturk:.4f}\")\n",
        "print(f\"\\nğŸ“‹ Classification Report:\\n\")\n",
        "print(classification_report(test_labels, y_pred_berturk, target_names=class_names))\n",
        "\n",
        "# Her Ã¶rnek iÃ§in detaylÄ± sonuÃ§\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"DETAYLI TAHMÄ°N SONUÃ‡LARI\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "results_list_berturk = []\n",
        "for i in range(len(test_texts)):\n",
        "    result = {\n",
        "        'Metin': test_texts[i],\n",
        "        'GerÃ§ek': class_names[test_labels[i]],\n",
        "        'Tahmin': class_names[y_pred_berturk[i]],\n",
        "        'DoÄŸru': 'âœ“' if test_labels[i] == y_pred_berturk[i] else 'âœ—'\n",
        "    }\n",
        "    results_list_berturk.append(result)\n",
        "    print(f\"\\n{i+1}. {result['Metin'][:50]}...\")\n",
        "    print(f\"   GerÃ§ek: {result['GerÃ§ek']}\")\n",
        "    print(f\"   Tahmin: {result['Tahmin']} {result['DoÄŸru']}\")\n",
        "\n",
        "# DataFrame olarak kaydet\n",
        "df_results_berturk = pd.DataFrame(results_list_berturk)\n",
        "df_results_berturk.to_csv('berturk_test_predictions.csv', index=False, encoding='utf-8-sig')\n",
        "print(\"\\nğŸ’¾ BERTurk tahminleri 'berturk_test_predictions.csv' dosyasÄ±na kaydedildi!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ELECTRA-TR - TEST SETÄ° TAHMÄ°NLERÄ°\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Model'i eval moduna al\n",
        "model_electra.eval()\n",
        "model_electra.to(device)\n",
        "\n",
        "# Test dataset oluÅŸtur\n",
        "test_dataset_electra = TurkishSentimentDataset(test_texts, test_labels, tokenizer_electra)\n",
        "\n",
        "# Tahminleri al\n",
        "predictions_electra = trainer_electra.predict(test_dataset_electra)\n",
        "y_pred_electra = np.argmax(predictions_electra.predictions, axis=1)\n",
        "\n",
        "# Accuracy hesapla\n",
        "accuracy_electra = accuracy_score(test_labels, y_pred_electra)\n",
        "\n",
        "print(f\"\\nğŸ“Š Test Accuracy: {accuracy_electra:.4f}\")\n",
        "print(f\"\\nğŸ“‹ Classification Report:\\n\")\n",
        "print(classification_report(test_labels, y_pred_electra, target_names=class_names))\n",
        "\n",
        "# Her Ã¶rnek iÃ§in detaylÄ± sonuÃ§\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"DETAYLI TAHMÄ°N SONUÃ‡LARI\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "results_list_electra = []\n",
        "for i in range(len(test_texts)):\n",
        "    result = {\n",
        "        'Metin': test_texts[i],\n",
        "        'GerÃ§ek': class_names[test_labels[i]],\n",
        "        'Tahmin': class_names[y_pred_electra[i]],\n",
        "        'DoÄŸru': 'âœ“' if test_labels[i] == y_pred_electra[i] else 'âœ—'\n",
        "    }\n",
        "    results_list_electra.append(result)\n",
        "    print(f\"\\n{i+1}. {result['Metin'][:50]}...\")\n",
        "    print(f\"   GerÃ§ek: {result['GerÃ§ek']}\")\n",
        "    print(f\"   Tahmin: {result['Tahmin']} {result['DoÄŸru']}\")\n",
        "\n",
        "# DataFrame olarak kaydet\n",
        "df_results_electra = pd.DataFrame(results_list_electra)\n",
        "df_results_electra.to_csv('electra_test_predictions.csv', index=False, encoding='utf-8-sig')\n",
        "print(\"\\nğŸ’¾ ElecTRa-TR tahminleri 'electra_test_predictions.csv' dosyasÄ±na kaydedildi!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Test Seti SonuÃ§larÄ±nÄ±n KarÅŸÄ±laÅŸtÄ±rÄ±lmasÄ±\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TEST SETÄ° - MODEL KARÅILAÅTIRMASI\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "test_comparison_df = pd.DataFrame({\n",
        "    'Model': ['BERTurk', 'ElecTRa-TR'],\n",
        "    'Test Accuracy': [accuracy_berturk, accuracy_electra],\n",
        "    'DoÄŸru Tahmin': [\n",
        "        (y_pred_berturk == test_labels).sum(),\n",
        "        (y_pred_electra == test_labels).sum()\n",
        "    ],\n",
        "    'YanlÄ±ÅŸ Tahmin': [\n",
        "        (y_pred_berturk != test_labels).sum(),\n",
        "        (y_pred_electra != test_labels).sum()\n",
        "    ],\n",
        "    'Toplam': [len(test_labels), len(test_labels)]\n",
        "})\n",
        "\n",
        "print(\"\\n\" + test_comparison_df.to_string(index=False))\n",
        "\n",
        "# En iyi test performansÄ±\n",
        "best_test_idx = test_comparison_df['Test Accuracy'].idxmax()\n",
        "print(f\"\\nğŸ† Test setinde en iyi model: {test_comparison_df.iloc[best_test_idx]['Model']}\")\n",
        "print(f\"   Accuracy: {test_comparison_df.iloc[best_test_idx]['Test Accuracy']:.4f}\")\n",
        "\n",
        "# KarÅŸÄ±laÅŸtÄ±rmalÄ± sonuÃ§larÄ± kaydet\n",
        "test_comparison_df.to_csv('test_set_comparison.csv', index=False)\n",
        "print(\"\\nğŸ’¾ KarÅŸÄ±laÅŸtÄ±rma sonuÃ§larÄ± 'test_set_comparison.csv' dosyasÄ±na kaydedildi!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Ã–zet ve Kaydedilen Dosyalar\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ğŸ“Š PROJE Ã–ZETÄ°\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\nâœ… Toplam eÄŸitim verisi: {len(df)}\")\n",
        "print(f\"âœ… Training set: {len(train_texts)} Ã¶rnek\")\n",
        "print(f\"âœ… Validation set: {len(val_texts)} Ã¶rnek\")\n",
        "print(f\"âœ… Test set: {len(test_texts)} Ã¶rnek\")\n",
        "\n",
        "print(f\"\\nâœ… EÄŸitilen modeller:\")\n",
        "print(f\"   1. BERTurk (dbmdz/bert-base-turkish-cased)\")\n",
        "print(f\"      - Validation F1: {results_berturk.get('eval_f1', 0):.4f}\")\n",
        "print(f\"      - Test Accuracy: {accuracy_berturk:.4f}\")\n",
        "print(f\"   2. ElecTRa-TR (dbmdz/electra-base-turkish-cased-discriminator)\")\n",
        "print(f\"      - Validation F1: {results_electra.get('eval_f1', 0):.4f}\")\n",
        "print(f\"      - Test Accuracy: {accuracy_electra:.4f}\")\n",
        "\n",
        "print(f\"\\nâœ… Kaydedilen model dizinleri:\")\n",
        "print(\"   - ./turkish_sentiment_bert-base-turkish-cased/\")\n",
        "print(\"   - ./turkish_sentiment_electra-base-turkish-cased-discriminator/\")\n",
        "\n",
        "print(f\"\\nâœ… Kaydedilen tahmin dosyalarÄ±:\")\n",
        "print(\"   - berturk_test_predictions.csv\")\n",
        "print(\"   - electra_test_predictions.csv\")\n",
        "print(\"   - test_set_comparison.csv\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ğŸ‰ TÃœM Ä°ÅLEMLER BAÅARIYLA TAMAMLANDI!\")\n",
        "print(\"=\"*60)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
